{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# api key 인증\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:\n",
      "        I know this:\n",
      "        Capital: Seoul\n",
      "        Language: Korean\n",
      "        Food: Kimchi and Bibimbap\n",
      "        Currency: South Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI:\\n        I know this:\\n        Capital: Seoul\\n        Language: Korean\\n        Food: Kimchi and Bibimbap\\n        Currency: South Korean Won')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# t = PromptTemplate.from_template('What is the capital of {country}')\n",
    "\n",
    "# t.format(country='France')\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# example_template = \"\"\"\n",
    "#     Human: {question}\n",
    "#     AI:{answer}\n",
    "# \"\"\"\n",
    "\n",
    "# example_template = PromptTemplate.from_template(example_template)\n",
    "example_prompt = PromptTemplate.from_template('Human : {question}\\nAI:{answer}')\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"Human : What do you know about {country}?\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "prompt.format(country='Germany')\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    'country':'Korea'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제들을 가져오고 예제들을 prompt를 사용해서 형식화 해주고 그런 다음 이를 fewShotPromptTemplate에 전달\n",
    "- fewShotPromptTemplate은 각각 예제들을 가져와 example prompt를 이용하여 형식화 해주고 그 다음 마지막으로 내용 마지막에 질문을 넣어줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        There are two Koreas - North Korea and South Korea\n",
      "        Capital of South Korea: Seoul\n",
      "        Language: Korean\n",
      "        Food: Kimchi and Bibimbap\n",
      "        Currency: South Korean Won\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        There are two Koreas - North Korea and South Korea\\n        Capital of South Korea: Seoul\\n        Language: Korean\\n        Food: Kimchi and Bibimbap\\n        Currency: South Korean Won\\n        ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# t = PromptTemplate.from_template('What is the capital of {country}')\n",
    "\n",
    "# t.format(country='France')\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# example_template = \"\"\"\n",
    "#     Human: {question}\n",
    "#     AI:{answer}\n",
    "# \"\"\"\n",
    "\n",
    "# example_template = PromptTemplate.from_template(example_template)\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('human', 'What do you know about {country}?'),\n",
    "    ('ai', '{answer}')\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a geography expert'),\n",
    "    example_prompt,\n",
    "    ('human', 'What do you know about {country}?')\n",
    "])\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    'country':'Korea'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human : What do you know about Germany?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# t = PromptTemplate.from_template('What is the capital of {country}')\n",
    "\n",
    "# t.format(country='France')\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# example_template = \"\"\"\n",
    "#     Human: {question}\n",
    "#     AI:{answer}\n",
    "# \"\"\"\n",
    "\n",
    "# example_template = PromptTemplate.from_template(example_template)\n",
    "example_prompt = PromptTemplate.from_template('Human : {question}\\nAI:{answer}')\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=10,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human : What do you know about {country}?\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "prompt.format(country='Germany')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 sample 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human : What do you know about Italy?\\nAI:\\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman : What do you know about Germany?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# t = PromptTemplate.from_template('What is the capital of {country}')\n",
    "\n",
    "# t.format(country='France')\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    \n",
    "    def __init__(self,examples):\n",
    "        self.examples = examples\n",
    "        \n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "    \n",
    "    def select_examples(self, input_variables):\n",
    "        from random import sample\n",
    "        \n",
    "        return sample(self.examples,k=1)\n",
    "\n",
    "# example_template = \"\"\"\n",
    "#     Human: {question}\n",
    "#     AI:{answer}\n",
    "# \"\"\"\n",
    "\n",
    "# example_template = PromptTemplate.from_template(example_template)\n",
    "example_prompt = PromptTemplate.from_template('Human : {question}\\nAI:{answer}')\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human : What do you know about {country}?\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "prompt.format(country='Germany')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Serialization and Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prompt load 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is the capital of Korea'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "# prompt = load_prompt('./prompt.json') # json 파일 형식\n",
    "prompt = load_prompt('./prompt.yaml') # yaml 파일 형식\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt.format(country = 'Korea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 많은 prompt들의 memory 등을 다 모으는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n    You are a role playing assistant.\\n    And you are impersonating a Pirate\\n\\n                                     \\n    \\n    This is an example of how you talk:\\n\\n    Human: What is your location?\\n    You: Arrrrg! That is a secret! Arg arg!!\\n\\n                              \\n    \\n    Start now!\\n\\n    Human: What is your favorite foods?\\n    You:\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "full_prompt.format(\n",
    "    character = 'Pirate',\n",
    "    example_question = 'What is your location?',\n",
    "    example_answer = 'Arrrrg! That is a secret! Arg arg!!',\n",
    "    question = 'What is your favorite foods?',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chain 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr matey! Me favorite grub be a hearty plate o' salted beef and hardtack! Aye, nothing beats the taste o' the sea! Arrr!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrr matey! Me favorite grub be a hearty plate o' salted beef and hardtack! Aye, nothing beats the taste o' the sea! Arrr!\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How to make Italin pasta?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [2.72s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere's how to make it:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for about 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is about 1/8 inch thick.\\n7. Cut the dough into your desired shape, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for about 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss it with your favorite sauce, such as marinara, alfredo, or pesto.\\n10. Serve hot and enjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere's how to make it:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for about 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is about 1/8 inch thick.\\n7. Cut the dough into your desired shape, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for about 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss it with your favorite sauce, such as marinara, alfredo, or pesto.\\n10. Serve hot and enjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"completion_tokens\": 241,\n",
      "      \"total_tokens\": 255,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere's how to make it:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for about 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is about 1/8 inch thick.\\n7. Cut the dough into your desired shape, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for about 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss it with your favorite sauce, such as marinara, alfredo, or pesto.\\n10. Serve hot and enjoy your homemade Italian pasta!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "set_llm_cache(InMemoryCache()) # 모든 response가 메모리에 저장\n",
    "set_debug(True) # log 같은게 보임\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    # streaming=True,\n",
    "    # callbacks=[\n",
    "    #     StreamingStdOutCallbackHandler(),\n",
    "    # ]\n",
    ")\n",
    "\n",
    "chat.predict('How to make Italin pasta?') # 3.6초 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cache을 이용하면 돈을 절약할 수 있음 왜냐하면 계속 반복되는 질문들에 대해서 답변을 새로 생성하는게 아니라 저장되게 하는 방법이기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere's how to make it:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for about 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is about 1/8 inch thick.\\n7. Cut the dough into your desired shape, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for about 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss it with your favorite sauce, such as marinara, Alfredo, or pesto.\\n10. Serve hot and enjoy your homemade Italian pasta!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict('How to make Italin pasta?') # 0초 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컴퓨터 데이터베이스에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere's how to make it:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for about 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is about 1/8 inch thick.\\n7. Cut the dough into your desired shape, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for about 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss it with your favorite sauce, such as marinara, pesto, or Alfredo.\\n\\nEnjoy your homemade Italian pasta!\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache('cache db')) # 컴퓨터 내 데이터에 저장\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    # streaming=True,\n",
    "    # callbacks=[\n",
    "    #     StreamingStdOutCallbackHandler(),\n",
    "    # ]\n",
    ")\n",
    "\n",
    "chat.predict('How to make Italin pasta?') # 3.6초 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 183\n",
      "\tPrompt Tokens: 13\n",
      "\tCompletion Tokens: 170\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0003595\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "with get_openai_callback() as usage:\n",
    "    chat.predict('What is recipe for beer?')\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients:\n",
      "- Water\n",
      "- Barley malt\n",
      "- Hops\n",
      "- Yeast\n",
      "\n",
      "Instructions:\n",
      "1. Malting: Barley grains are soaked in water, germinated, and then dried in a kiln to produce malted barley.\n",
      "2. Mashing: The malted barley is crushed and mixed with hot water to extract sugars. This mixture is then strained to create a liquid called wort.\n",
      "3. Boiling: The wort is boiled and hops are added to provide bitterness and aroma to the beer.\n",
      "4. Fermentation: The boiled wort is cooled and yeast is added to ferment the sugars into alcohol and carbon dioxide.\n",
      "5. Conditioning: The beer is aged for a period of time to allow flavors to develop and mature.\n",
      "6. Packaging: The beer is filtered, carbonated, and packaged for distribution and consumption. Ingredients:\n",
      "- Grapes (red or white)\n",
      "- Yeast\n",
      "- Sugar\n",
      "\n",
      "Instructions:\n",
      "1. Harvest the grapes and remove them from the stems.\n",
      "2. Crush the grapes to release the juice.\n",
      "3. Add yeast to the grape juice to start the fermentation process.\n",
      "4. Stir in sugar to feed the yeast and increase the alcohol content.\n",
      "5. Cover the mixture with a cloth and let it ferment for several weeks, stirring occasionally.\n",
      "6. Once fermentation is complete, strain the liquid to remove any solids.\n",
      "7. Transfer the liquid to a clean container and let it age for several months to develop flavor.\n",
      "8. Bottle the wine and store it in a cool, dark place until ready to drink. Enjoy! \n",
      "\n",
      "Tokens Used: 158\n",
      "\tPrompt Tokens: 13\n",
      "\tCompletion Tokens: 145\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0003095\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict('What is recipe for beer?')\n",
    "    b = chat.predict('What is recipe for wine?')\n",
    "    print(a,b,'\\n')\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Serialization(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "chat = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=450,\n",
    "    model='gpt-3.5-turbo-16'\n",
    ")\n",
    "\n",
    "chat.save('model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 불러오기(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yjroh\\Documents\\Python\\Self-Study\\AI\\env\\Lib\\site-packages\\langchain\\llms\\openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\yjroh\\Documents\\Python\\Self-Study\\AI\\env\\Lib\\site-packages\\langchain\\llms\\openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIChat(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-16', model_kwargs={'temperature': 0.1, 'max_tokens': 450, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "chat = load_llm('model.json')\n",
    "\n",
    "chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
