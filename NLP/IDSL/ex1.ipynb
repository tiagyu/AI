{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "valid = pd.read_csv('valid.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>body</th>\n",
       "      <th>caption</th>\n",
       "      <th>headline_id</th>\n",
       "      <th>body_id</th>\n",
       "      <th>category</th>\n",
       "      <th>classcode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>여성단체 \"김학의·장자연 사건 본질은 성착취·폭력\"</td>\n",
       "      <td>피해 당사자들도 증언 \"더는 악행 없도록 엄벌해달라\"</td>\n",
       "      <td>한국여성단체연합·한국여성의전화 등 여성시민사회단체 회원들은 22일 \"김학의 전 법무...</td>\n",
       "      <td>권력층 범죄 은폐ㆍ조작한 검찰 규탄 기자회견22일 서울 종로구 세종문화회관 계단에서...</td>\n",
       "      <td>AKR20190522103251005</td>\n",
       "      <td>AKR20190522103251005</td>\n",
       "      <td>4</td>\n",
       "      <td>501001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>코로나19·여름 대작 틈바구니서 공포 영화 실종</td>\n",
       "      <td>NaN</td>\n",
       "      <td>공포 영화는 여름이라는 과거 공식이 깨진 데다 올해 극장가가 신종 코로나바이러스 감...</td>\n",
       "      <td>비바리움 포스터시네마 어덜트 베케이션</td>\n",
       "      <td>AKR20200731132800005</td>\n",
       "      <td>AKR20200731132800005</td>\n",
       "      <td>4</td>\n",
       "      <td>712001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>광주 119소방동요 경연에서 빛고을유치원·월곡초 대상</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제21회 광주시 119소방동요 경연대회에서 빛고을유치원과 월곡초등학교가 각각 대상을...</td>\n",
       "      <td>대상받은 빛고을유치원.대상받은 월곡초등학교.</td>\n",
       "      <td>AKR20190614139900054</td>\n",
       "      <td>AKR20190614139900054</td>\n",
       "      <td>7</td>\n",
       "      <td>503003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                       subtitle  \\\n",
       "0   여성단체 \"김학의·장자연 사건 본질은 성착취·폭력\"  피해 당사자들도 증언 \"더는 악행 없도록 엄벌해달라\"   \n",
       "1     코로나19·여름 대작 틈바구니서 공포 영화 실종                            NaN   \n",
       "2  광주 119소방동요 경연에서 빛고을유치원·월곡초 대상                            NaN   \n",
       "\n",
       "                                                body  \\\n",
       "0  한국여성단체연합·한국여성의전화 등 여성시민사회단체 회원들은 22일 \"김학의 전 법무...   \n",
       "1  공포 영화는 여름이라는 과거 공식이 깨진 데다 올해 극장가가 신종 코로나바이러스 감...   \n",
       "2  제21회 광주시 119소방동요 경연대회에서 빛고을유치원과 월곡초등학교가 각각 대상을...   \n",
       "\n",
       "                                             caption           headline_id  \\\n",
       "0  권력층 범죄 은폐ㆍ조작한 검찰 규탄 기자회견22일 서울 종로구 세종문화회관 계단에서...  AKR20190522103251005   \n",
       "1                               비바리움 포스터시네마 어덜트 베케이션  AKR20200731132800005   \n",
       "2                           대상받은 빛고을유치원.대상받은 월곡초등학교.  AKR20190614139900054   \n",
       "\n",
       "                body_id  category  classcode  label  \n",
       "0  AKR20190522103251005         4     501001      0  \n",
       "1  AKR20200731132800005         4     712001      0  \n",
       "2  AKR20190614139900054         7     503003      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 분리\n",
    "target = 'label'\n",
    "\n",
    "# train x,y 분리\n",
    "x_train = train.drop(target,axis=1)\n",
    "y_train = train.loc[:,target]\n",
    "\n",
    "# valid x,y 분리\n",
    "x_valid = valid.drop(target,axis=1)\n",
    "y_valid = valid.loc[:,target]\n",
    "\n",
    "# test x,y 분리\n",
    "x_test = test.drop(target,axis=1)\n",
    "y_test = test.loc[:,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (194860, 8)\n",
      "x_valid : (10826, 8)\n",
      "x_test : (10826, 8)\n"
     ]
    }
   ],
   "source": [
    "print('x_train :',x_train.shape)\n",
    "print('x_valid :',x_valid.shape)\n",
    "print('x_test :',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 불용어 리스트\n",
    "korean_stop_words = ['이', '그', '저', '그리고', '하지만', '그래서']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=korean_stop_words, max_df=0.9, min_df=1)\n",
    "x_train_vectorized = vectorizer.fit_transform(x_train)\n",
    "x_valid_vectorized = vectorizer.transform(x_valid)\n",
    "x_test_vectorized = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n",
      "(8, 8)\n",
      "(8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_vectorized.shape)  # (194860, n_features)\n",
    "print(x_valid_vectorized.shape)  # (valid_samples, n_features)\n",
    "print(x_test_vectorized.shape)   # (test_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194860, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8, 194860]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m LinearSVC()\n\u001b[1;32m----> 2\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(x_train_vectorized, y_train)\n",
      "File \u001b[1;32mc:\\Users\\yjroh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yjroh\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:300\u001b[0m, in \u001b[0;36mLinearSVC.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m        An instance of the estimator.\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    301\u001b[0m         X,\n\u001b[0;32m    302\u001b[0m         y,\n\u001b[0;32m    303\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    304\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    305\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    306\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\yjroh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\yjroh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1165\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1165\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\yjroh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8, 194860]"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(x_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194860,)\n",
      "(194860, 8)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
